{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Artificial Neural Networks\n",
    "\n",
    "#### Introduction\n",
    "\n",
    "ANNs aim to simulate the processing in human brain by stringing together nodes of computation in a network. In human brain, the neurons are connected to other neurons by axons in a continuous manner. In other words, there is no real distinction among the neurons that a given neuron is connected to. In contrast, the ANNs compartmentalize the neurons into layers for computation. A feed-forward network arranges the layers in a sequential layers in which a neuron in a given layer is connected to neurons in layers preceding as well as succeeding it.\n",
    "\n",
    "Each neuron in a layer has a weight associated with it linking it back to a specific neuron in the preceding layer. This weight is used to compute the values of feature vectors in \"forward propagation\". The same weights are used to compute the gradient and update the weights during \"back propagation\".\n",
    "\n",
    "#### Mechanics of ANN implementation\n",
    "\n",
    "We will leverage a high-level module called `keras` for writing the ANNs and performing all the analysis. *Keras* abstracts the details of a NN and lets us focus on analyzing the data. It has the ability to employ multiple *packages* for actual NN processing such as feed-forward and back-propagation computations. We will be using `tensorflow` for actual neural network processing.  This module has the ability to parallelize the linear algebra computations across `gpu`s if available on a machine. Other packages that can work with Keras are *Microsoft CNTK* and *Theano*.\n",
    "\n",
    "We use the **eye state Detection** data from the UCI repository as previously discussed. The data is loaded into a *numpy* array and split into training and testing sets.\n",
    "\n",
    "#### First Pass\n",
    "\n",
    "Running a basic feed-forward network with `Keras` gives us the following results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "import numpy as np\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MaxAbsScaler, MinMaxScaler\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Variables, global\n",
    "iterations = 200\n",
    "batch_size = 1000\n",
    "# Good: RobustScaler()\n",
    "scalarX = MinMaxScaler()\n",
    "train_file = \"data\\eye_state.csv\"\n",
    "LABEL_POS = 14\n",
    "# Original: 256,128,20\n",
    "INPUT_NEURONS = 64\n",
    "HIDDEN_NEURONS = 32\n",
    "HIDDEN_LAYERS = 1\n",
    "\n",
    "# Functions\n",
    "def readNp(file, scalarX, label_pos):\n",
    "    data = np.loadtxt(file, delimiter=',', skiprows=1)\n",
    "    X = data[:, 0:label_pos]\n",
    "    Y = data[:, label_pos]\n",
    "    scalarX = scalarX.fit(X)\n",
    "    X = scalarX.transform(X)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=7)\n",
    "    Y_train = Y_train.astype(int)\n",
    "    Y_test = Y_test.astype(int)\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "def define_model(input_dim, in_neurons, out_neurons, hidden_dim, num_hidden_layer, is_dropout, output_act,\n",
    "                 other_act='relu'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(in_neurons, input_dim=input_dim, kernel_initializer='normal', activation=other_act))\n",
    "    if is_dropout:\n",
    "        model.add(Dropout(0.2))\n",
    "    for i in range(num_hidden_layer):\n",
    "        model.add(Dense(hidden_dim, kernel_initializer='normal', activation=other_act))\n",
    "        if is_dropout:\n",
    "            model.add(Dropout(0.2))\n",
    "    model.add(Dense(out_neurons, kernel_initializer='normal', activation=output_act))\n",
    "    return model\n",
    "# End functions\n",
    "\n",
    "# Step 1: Read data\n",
    "X_train, X_test, Y_train, Y_test = readNp(train_file, scalarX, LABEL_POS)\n",
    "print(\"X rows:{} features:{} Y rows:{}\".format(X_train.shape[0], X_train.shape[1], Y_train.shape[0]))\n",
    "\n",
    "# Step 2: Create model\n",
    "model = define_model(X_train.shape[1], INPUT_NEURONS, 1, HIDDEN_NEURONS, HIDDEN_LAYERS, True, 'sigmoid')\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# class_weights = class_weight.compute_class_weight('balanced', np.unique(Y_train), Y_train)\n",
    "history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=iterations, verbose=0)\n",
    "\n",
    "# Step 3: Evaluation\n",
    "start = timer()\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\n",
    "    \"Model evaluation done:{} sec.\\n Test-> loss:{} accuracy:{}\".format(round(timer() - start, 2), score[0], score[1]))\n",
    "Y_pred = model.predict(X_test).astype(int)\n",
    "matrix = confusion_matrix(Y_test, Y_pred)\n",
    "print(matrix)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
